{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzunafwJlvCZSz6ygYEBVk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrianortega93/Paradigmas-de-Programacion/blob/main/Tarea1_Desafio_Ortega_Adrian.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"text-align: center;\">\n",
        "    <h2>Universidad Casa Grande</h2>\n",
        "    <h3>Maestría en Inteligencia Artificial y Ciencia de Datos</h3>\n",
        "    <p><strong>Autor:</strong> Adrián Ortega Q.</p>\n",
        "</div>\n",
        "<div style=\"text-align: center;\">\n",
        "    <h3>Tarea 1 (Desafío)</h3>\n",
        "</div>"
      ],
      "metadata": {
        "id": "0Hi0rs1WdEkJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "fOc8d63KIu8Q"
      },
      "outputs": [],
      "source": [
        "# =======================================================================================\n",
        "# Tarea 1 (Desafío): Construcción de un Pipeline de Clasificación y Análisis de Modelos\n",
        "# Curso: Paradigmas de Programación para IA y Ciencia de Datos\n",
        "# Creado por: Adrián Ortega Q.\n",
        "# =======================================================================================\n",
        "\n",
        "# ---------------------------------------------------------------------------------------\n",
        "# Análisis Exploratorio y Preparación de Datos (Como se vio en la práctica)\n",
        "# ---------------------------------------------------------------------------------------\n",
        "print(\"\\n--- Análisis Exploratorio y Preparación de Datos (Como se vio en la práctica) ---\")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Componentes clave de Scikit-learn para el desafío\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "print(\"Tarea 1 (Desafío): Librerías cargadas.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------------------------------\n",
        "# Identificación y División de Datos\n",
        "# ---------------------------------------------------------------------------------------\n",
        "\n",
        "# Para esta tarea cargaremos los datos desde un archivo ai4i2020.csv,\n",
        "dataFile = 'ai4i2020.csv'\n",
        "\n",
        "try:\n",
        "  print(\"\\n--- Identificación y División de Datos ---\")\n",
        "  print(\"Tarea 1 (Desafío): DataFrame\")\n",
        "  # Cargar los datos desde el archivo ai4i2020.csv\n",
        "  dfFrame = pd.read_csv(dataFile)\n",
        "  #print(dfFrame)\n",
        "\n",
        "  # a) Identificar características y objetivo\n",
        "  camposDescartados = ['UDI', 'Product ID']\n",
        "  X = dfFrame.drop(camposDescartados, axis=1)\n",
        "  y = dfFrame['Machine failure']\n",
        "  #print(X)\n",
        "\n",
        "  # b) Separar columnas por tipo\n",
        "  numeric_features = ['Air temperature [K]', 'Process temperature [K]', 'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]', 'TWF',  'HDF',  'PWF',  'OSF',  'RNF' ]\n",
        "  categorical_features = ['Type']\n",
        "\n",
        "  # c) División en entrenamiento y prueba (¡fundamental para una evaluación honesta!)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
        "  print(f\"\\nDatos divididos: {len(X_train)} para entrenamiento, {len(X_test)} para prueba.\")\n",
        "\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: El archivo '{dfFrame}' no se encontró. Asegúrate de que la ruta sea correcta.\")\n",
        "except Exception as e:\n",
        "    print(f\"Ocurrió un error: {e}\")\n"
      ],
      "metadata": {
        "id": "Rfi5Y4q0JFVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------------------------------\n",
        "# Pipeline de Preprocesamiento Automatizado (Aplicando POO y el Paradigma Descriptivo)\n",
        "# ---------------------------------------------------------------------------------------\n",
        "print(\"\\n--- Pipeline de Preprocesamiento Automatizado (Aplicando POO y el Paradigma Descriptivo) ---\")\n",
        "\n",
        "# ---------------------------- Paradigma Orientado a Objetos ----------------------------\n",
        "# Enfoque: Encapsulamos la lógica de pipelines y como mezclarlos\n",
        "# La función preprocessor devolverá ColumnTransformer\n",
        "\n",
        "class ProcesamientoModel:\n",
        "\n",
        "  def __init__(self, numeric_features: list, categorical_features: list):\n",
        "    \"\"\"\n",
        "     Constructor para ProcesamientoModel.\n",
        "     Args:\n",
        "      numeric_features (list): Lista numérica.\n",
        "      categorical_features (list): Lista categórica.\n",
        "    \"\"\"\n",
        "    self.numeric_features = numeric_features\n",
        "    self.categorical_features = categorical_features\n",
        "\n",
        "  def get_preprocess(self):\n",
        "    \"\"\"\n",
        "     Crea y retorna un ColumnTransformer para el preprocesamiento de datos,\n",
        "     usando las características definidas en el constructor.\n",
        "    \"\"\"\n",
        "    # Aquí se aplica el enfoque Descriptivo\n",
        "    # ya que se declara lo que se necesita de Pipeline\n",
        "    numeric_pipeline = Pipeline(steps=[\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "    categorical_pipeline = Pipeline(steps=[\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ])\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_pipeline, self.numeric_features),\n",
        "            ('cat', categorical_pipeline, self.categorical_features)\n",
        "        ],\n",
        "        remainder='passthrough' # Mantiene columnas no especificadas (si las hubiera)\n",
        "    )\n",
        "    print(\"Preprocesador (ColumnTransformer) creado exitosamente.\")\n",
        "    return preprocessor\n",
        "\n",
        "# --- Demostración de uso ---\n",
        "# Se instancia la clase y se llama a la función\n",
        "numeric_selector = ProcesamientoModel(numeric_features, categorical_features)\n",
        "numeric_selector.get_preprocess()\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZwaOFBRRs_sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------------------------------\n",
        "# Comparación de Modelos dentro de un Pipeline Completo\n",
        "# ---------------------------------------------------------------------------------------\n",
        "\n",
        "print(\"\\n--- Comparación de Modelos dentro de un Pipeline Completo ---\")\n",
        "\n",
        "#Asignamos a una variable la funcion que se instanció de la clase ProcesamientoModel\n",
        "preprocessor = numeric_selector.get_preprocess()\n",
        "\n",
        "# a) Pipeline con Regresión Logística\n",
        "pipeline_logreg = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(random_state=42))\n",
        "])\n",
        "\n",
        "# b) Pipeline con Random Forest\n",
        "pipeline_rf = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# c) Entrenar y evaluar cada modelo para su commparación\n",
        "print(\"\\n==*Entrenando modelo de Regresión Logística*==\")\n",
        "pipeline_logreg.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\n=== Evaluación de Regresión Logística ===\")\n",
        "predictions_logreg = pipeline_logreg.predict(X_test)\n",
        "print(classification_report(y_test, predictions_logreg))\n",
        "\n",
        "print(\"==*Entrenando modelo de Random Forest*==\")\n",
        "pipeline_rf.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\n=== Evaluación de Random Forest ===\")\n",
        "predictions_rf = pipeline_rf.predict(X_test)\n",
        "print(classification_report(y_test, predictions_rf))\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "xjO16izsCQOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------------------------------\n",
        "#  Análisis Profundo del Mejor Modelo\n",
        "# ---------------------------------------------------------------------------------------\n",
        "\n",
        "# Obtener los reportes en forma de diccionario\n",
        "report_logreg = classification_report(y_test, predictions_logreg, output_dict=True)\n",
        "report_rf = classification_report(y_test, predictions_rf, output_dict=True)\n",
        "\n",
        "# Crear la tabla comparativa con las métricas promedio\n",
        "comparacion = pd.DataFrame({\n",
        "    'Precisión': [\n",
        "        report_logreg['weighted avg']['precision'],\n",
        "        report_rf['weighted avg']['precision']\n",
        "    ],\n",
        "    'Recall': [\n",
        "        report_logreg['weighted avg']['recall'],\n",
        "        report_rf['weighted avg']['recall']\n",
        "    ],\n",
        "    'F1-score': [\n",
        "        report_logreg['weighted avg']['f1-score'],\n",
        "        report_rf['weighted avg']['f1-score']\n",
        "    ],\n",
        "    'Accuracy': [\n",
        "        accuracy_score(y_test, predictions_logreg),\n",
        "        accuracy_score(y_test, predictions_rf)\n",
        "    ]\n",
        "}, index=['Regresión Logística', 'Random Forest'])\n",
        "\n",
        "# Redondear para mejor visualización\n",
        "comparacion = comparacion.round(4)\n",
        "\n",
        "print(\"\\n=== Comparación de modelos ===\")\n",
        "print(comparacion)\n"
      ],
      "metadata": {
        "id": "Qn56mc-VRGOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Selección y Justificación:**\n",
        "\n",
        "Aunque ambos modelos muestran un rendimiento excepcional, el Random Forest es marginalmente superior a la Regresión Logística debido a su Recall perfecto (1.00) para la clase '1' (Fallo).\n",
        "\n",
        "En el contexto de la predicción de fallos de maquinaria, la capacidad de detectar cada fallo real es de suma importancia para la toma de decisiones de negocio y para evitar interrupciones operacionales y costos asociados. Un Recall del 1.00 garantiza que ninguna máquina en riesgo de fallo pase desapercibida por el modelo. Dado que la Precisión y Accuracy son igualmente perfectas para ambos, el Random Forest ofrece la máxima seguridad en la detección de fallos.\n",
        "\n"
      ],
      "metadata": {
        "id": "r5A7Gm4bT5X4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# 5. Análisis de Importancia de Características:\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"\\n--- 5. ANÁLISIS DEL MEJOR MODELO EN ESTE CASO RANDOM FOREST---\")\n",
        "\n",
        "# a) Extraer la importancia de las características\n",
        "# El pipeline nos ayuda a acceder a los pasos internos.\n",
        "modelo_final_rf = pipeline_rf.named_steps['classifier']\n",
        "feature_importances = modelo_final_rf.feature_importances_\n",
        "\n",
        "# b) Obtener los nombres de las características DESPUÉS del preprocesamiento\n",
        "# El OneHotEncoder crea nuevos nombres de columnas.\n",
        "feature_names_raw = pipeline_rf.named_steps['preprocessor'].get_feature_names_out()\n",
        "\n",
        "# c) Crear un DataFrame para una fácil visualización\n",
        "importances_df = pd.DataFrame({\n",
        "    'feature': feature_names_raw,\n",
        "    'importance': feature_importances\n",
        "}).sort_values(by='importance', ascending=False)\n",
        "\n",
        "top_5_features = importances_df.head(5)\n",
        "print(\"\\nTop 5 características más importantes:\")\n",
        "print(top_5_features)\n",
        "\n",
        "# d) Visualizar la importancia de las características\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x='importance', y='feature', data=top_5_features)\n",
        "plt.title('Top 5 Características más Importantes (Random Forest)')\n",
        "plt.xlabel('Importancia')\n",
        "plt.ylabel('Característica')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"\\n¡Desafío completado, Juro solemnemente que mis intenciones no son buenas! :D.\")"
      ],
      "metadata": {
        "id": "YYAsFsb7IZ38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretación de negocio.**\n",
        "\n",
        "Antes de emitir este parrafo realicé una prueba omitiendo los campos 'TWF',  'HDF',  'PWF',  'OSF',  'RNF'\n",
        "donde el resultado es el siguiente.\n",
        "\n",
        "Top 5 características más importantes:\n",
        "\n",
        "                       feature | importance\n",
        "8 |  remainder__Machine failure  |  0.804776\n",
        "\n",
        "3   |          num__Torque [Nm]  |  0.102462\n",
        "\n",
        "2 | num__Rotational speed [rpm]  |  0.043514\n",
        "\n",
        "4  |       num__Tool wear [min]  | 0.023067\n",
        "\n",
        "0 |    num__Air temperature [K]   | 0.012664\n",
        "\n",
        "\n",
        "\n",
        "Donde me percaté que los resultados esperados daban exactamente el mismo para ambos casos Regresión Logística y Ramdom Forest.\n",
        "\n",
        "Lo que me llega a dejar en claro que esos campos se deben tener en consideracion ya que no habría diferencia por no tomarse en consideración mas variables.\n",
        "\n",
        "Sinceramente no entiendo bien el enfoque a donde va dirigido esta métrica pero evaluando los resultados de acuerdo a las pruebas puedo decir que me enfocaría en las caracteristicas que tienen mayor importancia, para mentener el mismo nivel y de ser posible mejorarlo.\n",
        "\n",
        "Mi humilde opinión como un gerente de planta 😶\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0eRyS3axYMVD"
      }
    }
  ]
}