{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+4WRyhPeOxxRmFodpX8r5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrianortega93/Paradigmas-de-Programacion/blob/main/ProyectoFinal_Ortega_Adrian.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"text-align: center; padding: 20px;\">\n",
        "\n",
        "  <h2 style=\"color: #2E86C1; margin-bottom: 5px;\">Universidad Casa Grande</h2>\n",
        "  <h3 style=\"color: #117864; margin-top: 0;\">Maestría en Inteligencia Artificial y Ciencia de Datos</h3>\n",
        "\n",
        "  <hr style=\"width: 60%; border: 1px solid #ccc; margin: 20px auto;\">\n",
        "\n",
        "  <h3 style=\"color: #884EA0; margin-bottom: 0;\">Proyecto Final (Avanzado)</h3>\n",
        "  <p style=\"font-size: 18px; margin-top: 5px;\"><em>Simulación de un Pipeline de ML de Producción en un Entorno de Notebook</em></p>\n",
        "\n",
        "  <p><strong>Autor:</strong> Adrian Ortega</p>\n",
        "  <p><strong>Curso:</strong> Paradigmas de Programación para Inteligencia Artificial y Análisis de Datos</p>\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "ZyT7tjVEM4v6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<p>Este proyecto simula un flujo completo de <strong>Machine Learning</strong> en producción utilizando <strong>principios de ingeniería de software</strong> dentro de un entorno Colab. Se eligió un dataset complejo del dominio financiero con múltiples desafíos:</p>\n",
        "\n",
        "<ul>\n",
        "  <li>Alta cardinalidad en variables categóricas.</li>\n",
        "  <li>Numerosos valores nulos en distintas columnas.</li>\n",
        "  <li>Clases desbalanceadas (casos de incumplimiento escasos).</li>\n",
        "  <li>Necesidad de un preprocesamiento diferenciado según tipo de dato.</li>\n",
        "</ul>\n",
        "\n",
        "<p>Se deja la ruta del archivo utilizado para este proyecto para una mejor visualización de su contenido y caracteristicas: <a href=\" https://www.kaggle.com/datasets/mishra5001/credit-card\">Credit Card Fraud Detection</a></p>\n",
        "\n",
        "<p>El proyecto se estructura mediante módulos virtuales usando <code>%%writefile</code>, pruebas unitarias, logging, tipado estático y generación de requerimientos.</p>\n"
      ],
      "metadata": {
        "id": "ANSz9EC7Ip8b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2 style=\"color:#117A65\">Configuración (config.py)</h2>\n",
        "\n",
        "<p>En este módulo definimos todas las variables clave del pipeline:</p>\n",
        "\n",
        "<ul>\n",
        "  <li>URL y nombre del dataset.</li>\n",
        "  <li>Columnas numéricas, categóricas, objetivo y columnas a eliminar.</li>\n",
        "  <li>Semilla aleatoria para reproducibilidad.</li>\n",
        "  <li>Parámetros del modelo y proporción del test set.</li>\n",
        "</ul>\n",
        "\n",
        "<p>Esta organización permite un mantenimiento limpio, evita \"números mágicos\" en el código y facilita modificar parámetros desde un único lugar.</p>\n"
      ],
      "metadata": {
        "id": "sT883VefKDq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile config.py\n",
        "# --------------------------------------------------------------------------------------------------------------\n",
        "#                       Módulo de configuración para el proyecto de Machine Learning.\n",
        "# --------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "import logging\n",
        "\n",
        "# ------- Rutas y Nombres de Archivos -------\n",
        "DATASET_URL = \"mishra5001/credit-card\"\n",
        "DATASET_FILE_NAME = 'application_data.csv'\n",
        "PIPELINE_NAME = 'trained_pipeline.joblib'\n",
        "\n",
        "# ------- Variables del Dataset -------\n",
        "TARGET_VARIABLE = 'TARGET'\n",
        "FEATURES_TO_DROP = ['SK_ID_CURR']\n",
        "\n",
        "# ------- Columnas numéricas, categóricas y de texto para el preprocesamiento. -------\n",
        "NUMERIC_FEATURES = [\n",
        "    'CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY',\n",
        "    'AMT_GOODS_PRICE', 'REGION_POPULATION_RELATIVE', 'DAYS_BIRTH', 'DAYS_EMPLOYED',\n",
        "    'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'OWN_CAR_AGE', 'CNT_FAM_MEMBERS',\n",
        "    'REGION_RATING_CLIENT', 'REGION_RATING_CLIENT_W_CITY', 'HOUR_APPR_PROCESS_START',\n",
        "    'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'APARTMENTS_AVG',\n",
        "    'BASEMENTAREA_AVG', 'YEARS_BEGINEXPLUATATION_AVG', 'YEARS_BUILD_AVG',\n",
        "    'COMMONAREA_AVG', 'ELEVATORS_AVG', 'ENTRANCES_AVG', 'FLOORSMAX_AVG',\n",
        "    'FLOORSMIN_AVG', 'LANDAREA_AVG', 'LIVINGAPARTMENTS_AVG', 'LIVINGAREA_AVG',\n",
        "    'NONLIVINGAPARTMENTS_AVG', 'NONLIVINGAREA_AVG', 'APARTMENTS_MODE',\n",
        "    'BASEMENTAREA_MODE', 'YEARS_BEGINEXPLUATATION_MODE', 'YEARS_BUILD_MODE',\n",
        "    'COMMONAREA_MODE', 'ELEVATORS_MODE', 'ENTRANCES_MODE', 'FLOORSMAX_MODE',\n",
        "    'FLOORSMIN_MODE', 'LANDAREA_MODE', 'LIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE',\n",
        "    'NONLIVINGAPARTMENTS_MODE', 'NONLIVINGAREA_MODE', 'APARTMENTS_MEDI',\n",
        "    'BASEMENTAREA_MEDI', 'YEARS_BEGINEXPLUATATION_MEDI', 'YEARS_BUILD_MEDI',\n",
        "    'COMMONAREA_MEDI', 'ELEVATORS_MEDI', 'ENTRANCES_MEDI', 'FLOORSMAX_MEDI',\n",
        "    'FLOORSMIN_MEDI', 'LANDAREA_MEDI', 'LIVINGAPARTMENTS_MEDI', 'LIVINGAREA_MEDI',\n",
        "    'NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAREA_MEDI', 'TOTALAREA_MODE',\n",
        "    'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE',\n",
        "    'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE',\n",
        "    'DAYS_LAST_PHONE_CHANGE', 'FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3',\n",
        "    'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7',\n",
        "    'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11',\n",
        "    'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15',\n",
        "    'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19',\n",
        "    'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21', 'AMT_REQ_CREDIT_BUREAU_HOUR',\n",
        "    'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK',\n",
        "    'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT',\n",
        "    'AMT_REQ_CREDIT_BUREAU_YEAR'\n",
        "]\n",
        "\n",
        "CATEGORICAL_FEATURES = [\n",
        "    'NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY',\n",
        "    'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE',\n",
        "    'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'WEEKDAY_APPR_PROCESS_START',\n",
        "    'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION',\n",
        "    'LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY',\n",
        "    'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY', 'ORGANIZATION_TYPE',\n",
        "    'FONDKAPREMONT_MODE', 'HOUSETYPE_MODE', 'WALLSMATERIAL_MODE',\n",
        "    'EMERGENCYSTATE_MODE', 'OCCUPATION_TYPE', 'FLAG_MOBIL', 'FLAG_EMP_PHONE',\n",
        "    'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE', 'FLAG_PHONE', 'FLAG_EMAIL'\n",
        "]\n",
        "\n",
        "# ------- Parámetros del Modelo y del Preprocesamiento -------\n",
        "TEST_SIZE = 0.25\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "MODEL_PARAMS = {\n",
        "    'n_estimators': 100,\n",
        "    'max_depth': 10,\n",
        "    'random_state': RANDOM_STATE\n",
        "}\n",
        "\n",
        "# ------- Configuración del Logging -------\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    datefmt='%Y-%m-%d %H:%M:%S'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvfqSa7f-feg",
        "outputId": "036490b6-36fc-49cc-ae84-ac30ca25e78d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting config.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2 style=\"color:#884EA0\">Preprocesamiento (processing.py)</h2>\n",
        "\n",
        "<p>El preprocesador se implementa como una clase que construye un <code>ColumnTransformer</code> complejo. Incluye:</p>\n",
        "\n",
        "<ul>\n",
        "  <li><strong>Numéricas</strong>: imputación con la mediana + escalado con <code>StandardScaler</code>.</li>\n",
        "  <li><strong>Categóricas</strong>: imputación por moda + <code>OneHotEncoder</code> con <code>handle_unknown='ignore'</code>.</li>\n",
        "  <li><strong>Desbalanceo</strong>: integración de <code>SMOTETomek</code>, que mejora el resampleo con <code>TomekLinks</code> para reducir ambigüedad.</li>\n",
        "</ul>\n",
        "\n",
        "<p>Este diseño modular permite aplicar técnicas adecuadas para cada tipo de dato en un flujo robusto y reutilizable.</p>\n"
      ],
      "metadata": {
        "id": "LQSqMh-yLJiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile processing.py\n",
        "# --------------------------------------------------------------------------------------------------------------\n",
        "#                                         Módulo de Procesamiento\n",
        "# --------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "from typing import List\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from imblearn.combine import SMOTETomek\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "\n",
        "class MLPreprocessor:\n",
        "    \"\"\"\n",
        "    Clase para construir un pipeline de preprocesamiento de datos modular y reutilizable.\n",
        "\n",
        "    Encapsula la lógica de transformación para características numéricas y categóricas.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, numeric_features: List[str], categorical_features: List[str]):\n",
        "        \"\"\"\n",
        "        Inicializa el preprocesador con listas de nombres de características.\n",
        "\n",
        "        Args:\n",
        "            numeric_features (List[str]): Lista de nombres de columnas numéricas.\n",
        "            categorical_features (List[str]): Lista de nombres de columnas categóricas.\n",
        "        \"\"\"\n",
        "        self.numeric_features = numeric_features\n",
        "        self.categorical_features = categorical_features\n",
        "\n",
        "    def get_column_transformer(self) -> ColumnTransformer:\n",
        "        \"\"\"\n",
        "        Crea y retorna un ColumnTransformer para el preprocesamiento de datos.\n",
        "\n",
        "        Este preprocesador aplica:\n",
        "        - Imputación de mediana y escalado estándar a las características numéricas.\n",
        "        - Imputación de moda y codificación One-Hot a las características categóricas.\n",
        "\n",
        "        Returns:\n",
        "            ColumnTransformer: El objeto ColumnTransformer configurado.\n",
        "        \"\"\"\n",
        "        numeric_pipeline = Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='median')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ])\n",
        "\n",
        "        categorical_pipeline = Pipeline(steps=[\n",
        "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "        ])\n",
        "\n",
        "        preprocessor = ColumnTransformer(\n",
        "            transformers=[\n",
        "                ('num', numeric_pipeline, self.numeric_features),\n",
        "                ('cat', categorical_pipeline, self.categorical_features)\n",
        "            ],\n",
        "            remainder='drop'\n",
        "        )\n",
        "        return preprocessor\n",
        "\n",
        "    def get_full_pipeline(self, model) -> ImbPipeline:\n",
        "        \"\"\"\n",
        "        Construye un pipeline completo que incluye preprocesamiento,\n",
        "        manejo de desbalance de clases y un modelo clasificador.\n",
        "\n",
        "        Args:\n",
        "            model: El modelo clasificador de Scikit-learn a utilizar.\n",
        "\n",
        "        Returns:\n",
        "            ImbPipeline: El pipeline completo.\n",
        "        \"\"\"\n",
        "        preprocessor = self.get_column_transformer()\n",
        "\n",
        "        pipeline = ImbPipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('sampler', SMOTETomek(tomek=TomekLinks(sampling_strategy='majority'))),\n",
        "            ('classifier', model)\n",
        "        ])\n",
        "        return pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7U7epfd-iyy",
        "outputId": "b8db61fe-a282-45a8-bfd9-a8654915f610"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting processing.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2 style=\"color:#B9770E\">Entrenamiento y Evaluación (train.py)</h2>\n",
        "\n",
        "<p>El script <code>train.py</code> ejecuta todo el flujo de entrenamiento:</p>\n",
        "\n",
        "<ol>\n",
        "  <li>Carga de datos desde Kaggle mediante <code>kagglehub</code>.</li>\n",
        "  <li>División en train/test con <code>stratify</code>.</li>\n",
        "  <li>Creación del pipeline con preprocesamiento + <code>RandomForestClassifier</code>.</li>\n",
        "  <li>Entrenamiento y evaluación con <code>accuracy, f1, precision, recall</code>.</li>\n",
        "  <li>Guardado del pipeline como <code>.joblib</code>.</li>\n",
        "</ol>\n",
        "\n",
        "<p>Además, se integró <strong>logging</strong> y <code>try...except</code> para registrar el flujo y manejar errores como <code>FileNotFoundError</code>.</p>\n"
      ],
      "metadata": {
        "id": "L78KVNckMNR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train.py\n",
        "# --------------------------------------------------------------------------------------------------------------\n",
        "#                                         Módulo de Entrenamiento\n",
        "# --------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import kagglehub\n",
        "import logging\n",
        "\n",
        "from typing import Dict, Any\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from processing import MLPreprocessor\n",
        "import config\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def run_training() -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Ejecuta el flujo completo de entrenamiento del modelo de Machine Learning.\n",
        "\n",
        "    Incluye la carga de datos, la división, la construcción del pipeline,\n",
        "    el entrenamiento, la evaluación y el guardado del modelo entrenado.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: Un diccionario con las métricas de rendimiento del modelo.\n",
        "    \"\"\"\n",
        "    logger.info(\"--- INICIANDO ENTRENAMIENTO ---\")\n",
        "\n",
        "    # ------- 1. Carga y preparación de los datos -------\n",
        "    logger.info(\"1. Cargando y dividiendo los datos...\")\n",
        "    try:\n",
        "        path = kagglehub.dataset_download(config.DATASET_URL)\n",
        "        csv_file_path = os.path.join(path, config.DATASET_FILE_NAME)\n",
        "\n",
        "        # Se procede solo a tomar los primeros 10k de registros para efectos de prueba\n",
        "        # ya que el archivo tiene mas de 300k y al ejecutarlo demora mucho\n",
        "        #df = pd.read_csv(csv_file_path)\n",
        "        df = pd.read_csv(csv_file_path, nrows=10000)\n",
        "    except FileNotFoundError as e:\n",
        "        logger.error(f\"Error al cargar el archivo: {e}\")\n",
        "        raise e\n",
        "\n",
        "    X = df.drop([config.TARGET_VARIABLE] + config.FEATURES_TO_DROP, axis=1)\n",
        "    y = df[config.TARGET_VARIABLE]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X,\n",
        "        y,\n",
        "        test_size=config.TEST_SIZE,\n",
        "        random_state=config.RANDOM_STATE,\n",
        "        stratify=y\n",
        "    )\n",
        "\n",
        "    # ------- 2. Creación del pipeline -------\n",
        "    logger.info(\"2. Creando el pipeline de preprocesamiento y modelo...\")\n",
        "    preprocessor = MLPreprocessor(\n",
        "        numeric_features=config.NUMERIC_FEATURES,\n",
        "        categorical_features=config.CATEGORICAL_FEATURES\n",
        "    )\n",
        "    model = RandomForestClassifier(**config.MODEL_PARAMS)\n",
        "    full_pipeline = preprocessor.get_full_pipeline(model)\n",
        "\n",
        "    # ------- 3. Entrenamiento del pipeline -------\n",
        "    logger.info(\"3. Entrenando el pipeline...\")\n",
        "    full_pipeline.fit(X_train, y_train)\n",
        "\n",
        "    # ------- 4. Evaluación del modelo -------\n",
        "    logger.info(\"4. Evaluando el modelo...\")\n",
        "    predictions = full_pipeline.predict(X_test)\n",
        "\n",
        "    metrics = {\n",
        "        'accuracy': accuracy_score(y_test, predictions),\n",
        "        'f1_score': f1_score(y_test, predictions, average='weighted'),\n",
        "        'precision': precision_score(y_test, predictions, average='weighted'),\n",
        "        'recall': recall_score(y_test, predictions, average='weighted')\n",
        "    }\n",
        "\n",
        "    logger.info(f\"Métricas de rendimiento:\\n{classification_report(y_test, predictions)}\")\n",
        "\n",
        "    # ------- 5. Guardado del pipeline -------\n",
        "    logger.info(\"5. Guardando el pipeline entrenado...\")\n",
        "    joblib.dump(full_pipeline, config.PIPELINE_NAME)\n",
        "    logger.info(f\"¡Entrenamiento finalizado y pipeline guardado en '{config.PIPELINE_NAME}'!\")\n",
        "\n",
        "    return metrics\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run_training()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnIQUkVy-llH",
        "outputId": "35a2de48-72ef-49b7-df52-1ffa98f03e85"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2 style=\"color:#566573\">Predicción (predict.py)</h2>\n",
        "\n",
        "<p>El módulo de predicción recibe una muestra como diccionario, carga el pipeline guardado y realiza la predicción.</p>\n",
        "\n",
        "<p>Incluye:</p>\n",
        "\n",
        "<ul>\n",
        "  <li>Carga segura del modelo entrenado.</li>\n",
        "  <li>Transformación del input a <code>DataFrame</code>.</li>\n",
        "  <li>Predicción y cálculo de probabilidades.</li>\n",
        "  <li>Formato interpretativo: <strong>\"Pago\"</strong> o <strong>\"Incumplimiento\"</strong>.</li>\n",
        "</ul>\n",
        "\n",
        "<p>El uso de <code>logging</code> y <code>warnings.filterwarnings</code> asegura trazabilidad y limpieza en la salida.</p>\n"
      ],
      "metadata": {
        "id": "b_j02-agOLWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile predict.py\n",
        "# --------------------------------------------------------------------------------------------------------------\n",
        "#                                         Módulo de Predicción\n",
        "# --------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "from typing import Dict, Any\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import logging\n",
        "\n",
        "import config\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# ------- Suprimimos las advertencias de versiones -------\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def make_prediction(input_data: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Realiza una predicción utilizando un pipeline entrenado.\n",
        "\n",
        "    Carga el pipeline guardado, prepara los datos de entrada y devuelve la\n",
        "    predicción y las probabilidades asociadas.\n",
        "\n",
        "    Args:\n",
        "        input_data (Dict[str, Any]): Un diccionario con los datos de entrada de una sola muestra.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: Un diccionario con la predicción, las probabilidades o un mensaje de error.\n",
        "    \"\"\"\n",
        "    logger.info(\"--- INICIANDO PREDICCIÓN ---\")\n",
        "\n",
        "    # ------- 1. Carga del pipeline entrenado -------\n",
        "    try:\n",
        "        pipeline = joblib.load(config.PIPELINE_NAME)\n",
        "    except FileNotFoundError:\n",
        "        logger.error(f\"Error: El pipeline entrenado no se encontró en '{config.PIPELINE_NAME}'.\")\n",
        "        return {'error': 'El pipeline entrenado no se encontró. Por favor, ejecuta train.py primero.'}\n",
        "\n",
        "    # ------- 2. Preparación de los datos de entrada -------\n",
        "    input_df = pd.DataFrame([input_data])\n",
        "\n",
        "    # ------- 3. Realizar la predicción -------\n",
        "    prediction = pipeline.predict(input_df)\n",
        "    probabilities = pipeline.predict_proba(input_df)\n",
        "\n",
        "    # ------- 4. Formatear la salida -------\n",
        "    prediction_label = 'Incumplimiento (Target=1)' if prediction[0] == 1 else 'Pago (Target=0)'\n",
        "\n",
        "    result = {\n",
        "        'prediction': prediction_label,\n",
        "        'probability_pago': probabilities[0][0],\n",
        "        'probability_incumplimiento': probabilities[0][1]\n",
        "    }\n",
        "\n",
        "    logger.info(\"Predicción realizada exitosamente.\")\n",
        "    logger.info(f\"Resultado: {result}\")\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJkfKzfE-n1v",
        "outputId": "1a392d77-c252-4b5e-b4f9-863c00026d21"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting predict.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2 style=\"color:#A93226\">Testing (test_processing.py)</h2>\n",
        "\n",
        "<p>Se desarrollaron pruebas con <code>pytest</code> para asegurar el correcto funcionamiento del pipeline:</p>\n",
        "\n",
        "<ul>\n",
        "  <li><strong>test_pipeline_output_dimensionality</strong>: verifica que la salida tenga la cantidad esperada de columnas.</li>\n",
        "  <li><strong>test_pipeline_handles_missing_values</strong>: comprueba que los valores nulos se imputen correctamente sin errores.</li>\n",
        "</ul>\n",
        "\n",
        "<p>Estas pruebas previenen errores en producción y aseguran que el pipeline sea tolerante a entradas reales.</p>\n"
      ],
      "metadata": {
        "id": "PkepX-S1PIRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_processing.py\n",
        "# --------------------------------------------------------------------------------------------------------------\n",
        "#                                         Módulo de Pruebas\n",
        "# --------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "import pytest\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from processing import MLPreprocessor\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Datos de prueba para simular el dataset\n",
        "# ------- 4. Formatear la salida -------\n",
        "@pytest.fixture\n",
        "def sample_data():\n",
        "    return pd.DataFrame({\n",
        "        'numeric_feature_1': [10, 20, None, 40],\n",
        "        'numeric_feature_2': [1.1, 2.2, 3.3, 4.4],\n",
        "        'categorical_feature': ['A', 'B', 'A', 'B']\n",
        "    })\n",
        "\n",
        "def get_features():\n",
        "    return ['numeric_feature_1', 'numeric_feature_2'], ['categorical_feature']\n",
        "\n",
        "# ------- Prueba 1: Verificar que el pipeline produce la dimensionalidad correcta -------\n",
        "def test_pipeline_output_dimensionality(sample_data):\n",
        "    numeric_features, categorical_features = get_features()\n",
        "    preprocessor = MLPreprocessor(numeric_features, categorical_features)\n",
        "    transformer = preprocessor.get_column_transformer()\n",
        "\n",
        "    X_transformed = transformer.fit_transform(sample_data)\n",
        "\n",
        "    assert X_transformed.shape[1] == 4\n",
        "\n",
        "# ------- Prueba 2: Verificar que el pipeline maneja y imputa valores nulos -------\n",
        "def test_pipeline_handles_missing_values(sample_data):\n",
        "    numeric_features, categorical_features = get_features()\n",
        "    preprocessor = MLPreprocessor(numeric_features, categorical_features)\n",
        "    transformer = preprocessor.get_column_transformer()\n",
        "\n",
        "    transformer.fit(sample_data)\n",
        "\n",
        "    X_transformed = transformer.transform(sample_data.iloc[2:3])\n",
        "\n",
        "    # El test ahora verifica que el valor imputado NO sea NaN,\n",
        "    # ya que el StandardScaler posterior cambia el valor numérico.\n",
        "    assert not np.isnan(X_transformed[0, 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QbSVC35-7CQ",
        "outputId": "53f9523e-b595-4efd-f843-0ddb43522c3f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test_processing.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2 style=\"color:#2471A3\">Orquestación</h2>\n",
        "\n",
        "<p>En esta sección:</p>\n",
        "\n",
        "<ol>\n",
        "  <li>Se ejecuta <code>run_training()</code> para entrenar y guardar el modelo.</li>\n",
        "  <li>Se selecciona una muestra real del dataset (una fila) y se realiza la predicción.</li>\n",
        "  <li>Se muestra la predicción junto con la probabilidad para cada clase.</li>\n",
        "</ol>\n",
        "\n",
        "<p>Esto demuestra que el pipeline funciona de extremo a extremo, desde la carga hasta la predicción.</p>\n",
        "\n",
        "<h2 style=\"color:#1ABC9C\">Reproducibilidad y Dependencias</h2>\n",
        "\n",
        "<p>Para garantizar la portabilidad y la ejecución en cualquier entorno, se generó un archivo <code>requirements.txt</code> con todas las dependencias del proyecto.</p>\n",
        "\n",
        "<p>Este archivo puede utilizarse con:</p>\n",
        "\n",
        "<pre><code>pip install -r requirements.txt</code></pre>\n",
        "\n",
        "<p>Esto asegura que otros usuarios puedan replicar el entorno exacto y obtener los mismos resultados.</p>\n",
        "\n"
      ],
      "metadata": {
        "id": "jV1nz7LCRG-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------------------------------------------------------\n",
        "#                                         Orquestación\n",
        "# --------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# ------- 1. Instalar pytest -------\n",
        "!pip install pytest > /dev/null\n",
        "\n",
        "# ------- 2. Ejecutar las pruebas unitarias -------\n",
        "!pytest test_processing.py\n",
        "\n",
        "# ------- 3. Importar las funciones de los scripts creados -------\n",
        "from train import run_training\n",
        "from predict import make_prediction\n",
        "\n",
        "\n",
        "# ------- Parte 1: Entrenamiento del modelo -------\n",
        "metrics_result = run_training()\n",
        "print(\"\\n--- ENTRENAMIENTO COMPLETO ---\")\n",
        "print(\"Métricas del modelo:\", metrics_result)\n",
        "\n",
        "# ------- Parte 2: Predicción usando una fila del dataset original -------\n",
        "import pandas as pd\n",
        "import os\n",
        "import kagglehub\n",
        "from config import DATASET_URL, DATASET_FILE_NAME\n",
        "\n",
        "print(\"\\n--- PREDICCIÓN CON UNA MUESTRA DEL DATASET ORIGINAL ---\")\n",
        "\n",
        "try:\n",
        "    # ------- Cargamos el dataset para poder seleccionar una fila de ejemplo -------\n",
        "    path = kagglehub.dataset_download(DATASET_URL)\n",
        "    csv_file_path = os.path.join(path, DATASET_FILE_NAME)\n",
        "    df_original = pd.read_csv(csv_file_path, nrows=10000)\n",
        "\n",
        "    # Seleccionamos la fila 3 (índice 2) como nuestra \"muestra\"\n",
        "    # y la convertimos a un diccionario para que make_prediction la pueda procesar\n",
        "    sample_data_from_df = df_original.iloc[2].to_dict()\n",
        "\n",
        "    # ------- Realizamos la predicción con esta fila -------\n",
        "    prediction_result = make_prediction(sample_data_from_df)\n",
        "\n",
        "    print(\"\\n--- PREDICCIÓN COMPLETA ---\")\n",
        "    print(prediction_result)\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error al cargar el archivo de datos original: {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"Ocurrió un error inesperado: {e}\")\n",
        "\n",
        "# ------- 4. Generar y mostrar el archivo de requerimientos -------\n",
        "print(\"\\nGenerando archivo de requerimientos (requirements.txt)...\")\n",
        "!pip freeze > requirements.txt\n",
        "print(\"\\n--- Contenido de requirements.txt ---\")\n",
        "!cat requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4j_93lkr-9tK",
        "outputId": "9aa9a041-b444-4577-fc85-f366ab9d3f4a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
            "platform linux -- Python 3.11.13, pytest-8.4.1, pluggy-1.6.0\n",
            "rootdir: /content\n",
            "plugins: anyio-4.9.0, langsmith-0.4.8, typeguard-4.4.4\n",
            "collected 2 items                                                              \u001b[0m\n",
            "\n",
            "test_processing.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                    [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 1.81s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
            "\n",
            "--- ENTRENAMIENTO COMPLETO ---\n",
            "Métricas del modelo: {'accuracy': 0.8956, 'f1_score': 0.8792752601401571, 'precision': 0.8656902205576361, 'recall': 0.8956}\n",
            "\n",
            "--- PREDICCIÓN CON UNA MUESTRA DEL DATASET ORIGINAL ---\n",
            "\n",
            "--- PREDICCIÓN COMPLETA ---\n",
            "{'prediction': 'Pago (Target=0)', 'probability_pago': np.float64(0.7997533881824829), 'probability_incumplimiento': np.float64(0.20024661181751713)}\n",
            "\n",
            "Generando archivo de requerimientos (requirements.txt)...\n",
            "\n",
            "--- Contenido de requirements.txt ---\n",
            "absl-py==1.4.0\n",
            "accelerate==1.9.0\n",
            "aiofiles==24.1.0\n",
            "aiohappyeyeballs==2.6.1\n",
            "aiohttp==3.12.15\n",
            "aiosignal==1.4.0\n",
            "alabaster==1.0.0\n",
            "albucore==0.0.24\n",
            "albumentations==2.0.8\n",
            "ale-py==0.11.2\n",
            "altair==5.5.0\n",
            "annotated-types==0.7.0\n",
            "antlr4-python3-runtime==4.9.3\n",
            "anyio==4.9.0\n",
            "anywidget==0.9.18\n",
            "argon2-cffi==25.1.0\n",
            "argon2-cffi-bindings==25.1.0\n",
            "array_record==0.7.2\n",
            "arviz==0.22.0\n",
            "astropy==7.1.0\n",
            "astropy-iers-data==0.2025.7.28.0.41.50\n",
            "astunparse==1.6.3\n",
            "atpublic==5.1\n",
            "attrs==25.3.0\n",
            "audioread==3.0.1\n",
            "autograd==1.8.0\n",
            "babel==2.17.0\n",
            "backcall==0.2.0\n",
            "backports.tarfile==1.2.0\n",
            "beautifulsoup4==4.13.4\n",
            "betterproto==2.0.0b6\n",
            "bigframes==2.12.0\n",
            "bigquery-magics==0.10.1\n",
            "bleach==6.2.0\n",
            "blinker==1.9.0\n",
            "blis==1.3.0\n",
            "blobfile==3.0.0\n",
            "blosc2==3.6.1\n",
            "bokeh==3.7.3\n",
            "Bottleneck==1.4.2\n",
            "bqplot==0.12.45\n",
            "branca==0.8.1\n",
            "Brotli==1.1.0\n",
            "build==1.2.2.post1\n",
            "CacheControl==0.14.3\n",
            "cachetools==5.5.2\n",
            "catalogue==2.0.10\n",
            "certifi==2025.7.14\n",
            "cffi==1.17.1\n",
            "chardet==5.2.0\n",
            "charset-normalizer==3.4.2\n",
            "chex==0.1.90\n",
            "clarabel==0.11.1\n",
            "click==8.2.1\n",
            "cloudpathlib==0.21.1\n",
            "cloudpickle==3.1.1\n",
            "cmake==3.31.6\n",
            "cmdstanpy==1.2.5\n",
            "colorcet==3.1.0\n",
            "colorlover==0.3.0\n",
            "colour==0.1.5\n",
            "community==1.0.0b1\n",
            "confection==0.1.5\n",
            "cons==0.4.7\n",
            "contourpy==1.3.3\n",
            "cramjam==2.11.0\n",
            "cryptography==43.0.3\n",
            "cuda-python==12.6.2.post1\n",
            "cudf-cu12 @ https://pypi.nvidia.com/cudf-cu12/cudf_cu12-25.6.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\n",
            "cudf-polars-cu12==25.6.0\n",
            "cufflinks==0.17.3\n",
            "cuml-cu12==25.6.0\n",
            "cupy-cuda12x==13.3.0\n",
            "curl_cffi==0.12.0\n",
            "cuvs-cu12==25.6.1\n",
            "cvxopt==1.3.2\n",
            "cvxpy==1.6.7\n",
            "cycler==0.12.1\n",
            "cyipopt==1.5.0\n",
            "cymem==2.0.11\n",
            "Cython==3.0.12\n",
            "dask==2025.5.0\n",
            "dask-cuda==25.6.0\n",
            "dask-cudf-cu12==25.6.0\n",
            "dataproc-spark-connect==0.8.3\n",
            "datasets==4.0.0\n",
            "db-dtypes==1.4.3\n",
            "dbus-python==1.2.18\n",
            "debugpy==1.8.15\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "diffusers==0.34.0\n",
            "dill==0.3.8\n",
            "distributed==2025.5.0\n",
            "distributed-ucxx-cu12==0.44.0\n",
            "distro==1.9.0\n",
            "dlib==19.24.6\n",
            "dm-tree==0.1.9\n",
            "docstring_parser==0.17.0\n",
            "docutils==0.21.2\n",
            "dopamine_rl==4.1.2\n",
            "duckdb==1.3.2\n",
            "earthengine-api==1.5.24\n",
            "easydict==1.13\n",
            "editdistance==0.8.1\n",
            "eerepr==0.1.2\n",
            "einops==0.8.1\n",
            "en_core_web_sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl#sha256=1932429db727d4bff3deed6b34cfc05df17794f4a52eeb26cf8928f7c1a0fb85\n",
            "entrypoints==0.4\n",
            "et_xmlfile==2.0.0\n",
            "etils==1.13.0\n",
            "etuples==0.3.10\n",
            "Farama-Notifications==0.0.4\n",
            "fastai==2.7.19\n",
            "fastapi==0.116.1\n",
            "fastcore==1.7.29\n",
            "fastdownload==0.0.7\n",
            "fastjsonschema==2.21.1\n",
            "fastprogress==1.0.3\n",
            "fastrlock==0.8.3\n",
            "ffmpy==0.6.1\n",
            "filelock==3.18.0\n",
            "firebase-admin==6.9.0\n",
            "Flask==3.1.1\n",
            "flatbuffers==25.2.10\n",
            "flax==0.10.6\n",
            "folium==0.20.0\n",
            "fonttools==4.59.0\n",
            "frozendict==2.4.6\n",
            "frozenlist==1.7.0\n",
            "fsspec==2025.3.0\n",
            "future==1.0.0\n",
            "gast==0.6.0\n",
            "gcsfs==2025.3.0\n",
            "GDAL==3.8.4\n",
            "gdown==5.2.0\n",
            "geemap==0.35.3\n",
            "geocoder==1.38.1\n",
            "geographiclib==2.0\n",
            "geopandas==1.1.1\n",
            "geopy==2.4.1\n",
            "gin-config==0.5.0\n",
            "gitdb==4.0.12\n",
            "GitPython==3.1.45\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-ai-generativelanguage==0.6.15\n",
            "google-api-core==2.25.1\n",
            "google-api-python-client==2.177.0\n",
            "google-auth==2.38.0\n",
            "google-auth-httplib2==0.2.0\n",
            "google-auth-oauthlib==1.2.2\n",
            "google-cloud-aiplatform==1.105.0\n",
            "google-cloud-bigquery==3.35.1\n",
            "google-cloud-bigquery-connection==1.18.3\n",
            "google-cloud-bigquery-storage==2.32.0\n",
            "google-cloud-core==2.4.3\n",
            "google-cloud-dataproc==5.21.0\n",
            "google-cloud-datastore==2.21.0\n",
            "google-cloud-firestore==2.21.0\n",
            "google-cloud-functions==1.20.4\n",
            "google-cloud-iam==2.19.1\n",
            "google-cloud-language==2.17.2\n",
            "google-cloud-resource-manager==1.14.2\n",
            "google-cloud-spanner==3.56.0\n",
            "google-cloud-storage==2.19.0\n",
            "google-cloud-translate==3.21.1\n",
            "google-colab @ file:///colabtools/dist/google_colab-1.0.0.tar.gz\n",
            "google-crc32c==1.7.1\n",
            "google-genai==1.27.0\n",
            "google-generativeai==0.8.5\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==2.7.2\n",
            "googleapis-common-protos==1.70.0\n",
            "googledrivedownloader==1.1.0\n",
            "gradio==5.38.2\n",
            "gradio_client==1.11.0\n",
            "graphviz==0.21\n",
            "greenlet==3.2.3\n",
            "groovy==0.1.2\n",
            "grpc-google-iam-v1==0.14.2\n",
            "grpc-interceptor==0.15.4\n",
            "grpcio==1.74.0\n",
            "grpcio-status==1.71.2\n",
            "grpclib==0.4.8\n",
            "gspread==6.2.1\n",
            "gspread-dataframe==4.0.0\n",
            "gym==0.25.2\n",
            "gym-notices==0.1.0\n",
            "gymnasium==1.2.0\n",
            "h11==0.16.0\n",
            "h2==4.2.0\n",
            "h5netcdf==1.6.3\n",
            "h5py==3.14.0\n",
            "hdbscan==0.8.40\n",
            "hf-xet==1.1.5\n",
            "hf_transfer==0.1.9\n",
            "highspy==1.11.0\n",
            "holidays==0.77\n",
            "holoviews==1.21.0\n",
            "hpack==4.1.0\n",
            "html5lib==1.1\n",
            "httpcore==1.0.9\n",
            "httpimport==1.4.1\n",
            "httplib2==0.22.0\n",
            "httpx==0.28.1\n",
            "huggingface-hub==0.34.3\n",
            "humanize==4.12.3\n",
            "hyperframe==6.1.0\n",
            "hyperopt==0.2.7\n",
            "ibis-framework==9.5.0\n",
            "idna==3.10\n",
            "imageio==2.37.0\n",
            "imageio-ffmpeg==0.6.0\n",
            "imagesize==1.4.1\n",
            "imbalanced-learn==0.13.0\n",
            "immutabledict==4.2.1\n",
            "importlib_metadata==8.7.0\n",
            "importlib_resources==6.5.2\n",
            "imutils==0.5.4\n",
            "inflect==7.5.0\n",
            "iniconfig==2.1.0\n",
            "intel-cmplr-lib-ur==2025.2.0\n",
            "intel-openmp==2025.2.0\n",
            "ipyevents==2.0.2\n",
            "ipyfilechooser==0.6.0\n",
            "ipykernel==6.17.1\n",
            "ipyleaflet==0.20.0\n",
            "ipyparallel==8.8.0\n",
            "ipython==7.34.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.5.0\n",
            "ipytree==0.2.2\n",
            "ipywidgets==7.7.1\n",
            "itsdangerous==2.2.0\n",
            "jaraco.classes==3.4.0\n",
            "jaraco.context==6.0.1\n",
            "jaraco.functools==4.2.1\n",
            "jax==0.5.3\n",
            "jax-cuda12-pjrt==0.5.3\n",
            "jax-cuda12-plugin==0.5.3\n",
            "jaxlib==0.5.3\n",
            "jeepney==0.9.0\n",
            "jieba==0.42.1\n",
            "Jinja2==3.1.6\n",
            "jiter==0.10.0\n",
            "joblib==1.5.1\n",
            "jsonpatch==1.33\n",
            "jsonpickle==4.1.1\n",
            "jsonpointer==3.0.0\n",
            "jsonschema==4.25.0\n",
            "jsonschema-specifications==2025.4.1\n",
            "jupyter-client==6.1.12\n",
            "jupyter-console==6.1.0\n",
            "jupyter-leaflet==0.20.0\n",
            "jupyter-server==1.16.0\n",
            "jupyter_core==5.8.1\n",
            "jupyter_kernel_gateway @ git+https://github.com/googlecolab/kernel_gateway@b134e9945df25c2dcb98ade9129399be10788671\n",
            "jupyterlab_pygments==0.3.0\n",
            "jupyterlab_widgets==3.0.15\n",
            "jupytext==1.17.2\n",
            "kaggle==1.7.4.5\n",
            "kagglehub==0.3.12\n",
            "keras==3.10.0\n",
            "keras-hub==0.21.1\n",
            "keras-nlp==0.21.1\n",
            "keyring==25.6.0\n",
            "keyrings.google-artifactregistry-auth==1.1.2\n",
            "kiwisolver==1.4.8\n",
            "langchain==0.3.27\n",
            "langchain-core==0.3.72\n",
            "langchain-text-splitters==0.3.9\n",
            "langcodes==3.5.0\n",
            "langsmith==0.4.8\n",
            "language_data==1.3.0\n",
            "launchpadlib==1.10.16\n",
            "lazr.restfulclient==0.14.4\n",
            "lazr.uri==1.0.6\n",
            "lazy_loader==0.4\n",
            "libclang==18.1.1\n",
            "libcudf-cu12 @ https://pypi.nvidia.com/libcudf-cu12/libcudf_cu12-25.6.0-py3-none-manylinux_2_28_x86_64.whl\n",
            "libcugraph-cu12==25.6.0\n",
            "libcuml-cu12==25.6.0\n",
            "libcuvs-cu12==25.6.1\n",
            "libkvikio-cu12==25.6.0\n",
            "libpysal==4.13.0\n",
            "libraft-cu12==25.6.0\n",
            "librmm-cu12==25.6.0\n",
            "librosa==0.11.0\n",
            "libucx-cu12==1.18.1\n",
            "libucxx-cu12==0.44.0\n",
            "lightgbm @ file:///tmp/lightgbm/LightGBM/dist/lightgbm-4.6.0-py3-none-linux_x86_64.whl\n",
            "linkify-it-py==2.0.3\n",
            "llvmlite==0.43.0\n",
            "locket==1.0.0\n",
            "logical-unification==0.4.6\n",
            "lxml==5.4.0\n",
            "Mako==1.1.3\n",
            "marisa-trie==1.2.1\n",
            "Markdown==3.8.2\n",
            "markdown-it-py==3.0.0\n",
            "MarkupSafe==3.0.2\n",
            "matplotlib==3.10.0\n",
            "matplotlib-inline==0.1.7\n",
            "matplotlib-venn==1.1.2\n",
            "mdit-py-plugins==0.4.2\n",
            "mdurl==0.1.2\n",
            "miniKanren==1.0.5\n",
            "missingno==0.5.2\n",
            "mistune==3.1.3\n",
            "mizani==0.13.5\n",
            "mkl==2025.2.0\n",
            "ml_dtypes==0.5.3\n",
            "mlxtend==0.23.4\n",
            "more-itertools==10.7.0\n",
            "moviepy==1.0.3\n",
            "mpmath==1.3.0\n",
            "msgpack==1.1.1\n",
            "multidict==6.6.3\n",
            "multipledispatch==1.0.0\n",
            "multiprocess==0.70.16\n",
            "multitasking==0.0.12\n",
            "murmurhash==1.0.13\n",
            "music21==9.3.0\n",
            "namex==0.1.0\n",
            "narwhals==2.0.1\n",
            "natsort==8.4.0\n",
            "nbclassic==1.3.1\n",
            "nbclient==0.10.2\n",
            "nbconvert==7.16.6\n",
            "nbformat==5.10.4\n",
            "ndindex==1.10.0\n",
            "nest-asyncio==1.6.0\n",
            "networkx==3.5\n",
            "nibabel==5.3.2\n",
            "nltk==3.9.1\n",
            "notebook==6.5.7\n",
            "notebook_shim==0.2.4\n",
            "numba==0.60.0\n",
            "numba-cuda==0.11.0\n",
            "numexpr==2.11.0\n",
            "numpy==2.0.2\n",
            "nvidia-cublas-cu12==12.5.3.2\n",
            "nvidia-cuda-cupti-cu12==12.5.82\n",
            "nvidia-cuda-nvcc-cu12==12.5.82\n",
            "nvidia-cuda-nvrtc-cu12==12.5.82\n",
            "nvidia-cuda-runtime-cu12==12.5.82\n",
            "nvidia-cudnn-cu12==9.3.0.75\n",
            "nvidia-cufft-cu12==11.2.3.61\n",
            "nvidia-curand-cu12==10.3.6.82\n",
            "nvidia-cusolver-cu12==11.6.3.83\n",
            "nvidia-cusparse-cu12==12.5.1.3\n",
            "nvidia-cusparselt-cu12==0.6.2\n",
            "nvidia-ml-py==12.575.51\n",
            "nvidia-nccl-cu12==2.23.4\n",
            "nvidia-nvjitlink-cu12==12.5.82\n",
            "nvidia-nvtx-cu12==12.4.127\n",
            "nvtx==0.2.12\n",
            "nx-cugraph-cu12 @ https://pypi.nvidia.com/nx-cugraph-cu12/nx_cugraph_cu12-25.6.0-py3-none-any.whl\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.3.1\n",
            "omegaconf==2.3.0\n",
            "openai==1.98.0\n",
            "opencv-contrib-python==4.12.0.88\n",
            "opencv-python==4.12.0.88\n",
            "opencv-python-headless==4.12.0.88\n",
            "openpyxl==3.1.5\n",
            "opt_einsum==3.4.0\n",
            "optax==0.2.5\n",
            "optree==0.17.0\n",
            "orbax-checkpoint==0.11.20\n",
            "orjson==3.11.1\n",
            "osqp==1.0.4\n",
            "packaging==25.0\n",
            "pandas==2.2.2\n",
            "pandas-datareader==0.10.0\n",
            "pandas-gbq==0.29.2\n",
            "pandas-stubs==2.2.2.240909\n",
            "pandocfilters==1.5.1\n",
            "panel==1.7.5\n",
            "param==2.2.1\n",
            "parso==0.8.4\n",
            "parsy==2.1\n",
            "partd==1.4.2\n",
            "patsy==1.0.1\n",
            "peewee==3.18.2\n",
            "peft==0.16.0\n",
            "pexpect==4.9.0\n",
            "pickleshare==0.7.5\n",
            "pillow==11.3.0\n",
            "platformdirs==4.3.8\n",
            "plotly==5.24.1\n",
            "plotnine==0.14.5\n",
            "pluggy==1.6.0\n",
            "ply==3.11\n",
            "polars==1.25.2\n",
            "pooch==1.8.2\n",
            "portpicker==1.5.2\n",
            "preshed==3.0.10\n",
            "prettytable==3.16.0\n",
            "proglog==0.1.12\n",
            "progressbar2==4.5.0\n",
            "prometheus_client==0.22.1\n",
            "promise==2.3\n",
            "prompt_toolkit==3.0.51\n",
            "propcache==0.3.2\n",
            "prophet==1.1.7\n",
            "proto-plus==1.26.1\n",
            "protobuf==5.29.5\n",
            "psutil==5.9.5\n",
            "psycopg2==2.9.10\n",
            "psygnal==0.14.0\n",
            "ptyprocess==0.7.0\n",
            "py-cpuinfo==9.0.0\n",
            "py4j==0.10.9.7\n",
            "pyarrow==18.1.0\n",
            "pyasn1==0.6.1\n",
            "pyasn1_modules==0.4.2\n",
            "pycairo==1.28.0\n",
            "pycocotools==2.0.10\n",
            "pycparser==2.22\n",
            "pycryptodomex==3.23.0\n",
            "pydantic==2.11.7\n",
            "pydantic_core==2.33.2\n",
            "pydata-google-auth==1.9.1\n",
            "pydot==3.0.4\n",
            "pydotplus==2.0.2\n",
            "PyDrive2==1.21.3\n",
            "pydub==0.25.1\n",
            "pyerfa==2.0.1.5\n",
            "pygame==2.6.1\n",
            "pygit2==1.18.1\n",
            "Pygments==2.19.2\n",
            "PyGObject==3.42.0\n",
            "PyJWT==2.10.1\n",
            "pylibcudf-cu12 @ https://pypi.nvidia.com/pylibcudf-cu12/pylibcudf_cu12-25.6.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\n",
            "pylibcugraph-cu12==25.6.0\n",
            "pylibraft-cu12==25.6.0\n",
            "pymc==5.25.1\n",
            "pynndescent==0.5.13\n",
            "pynvjitlink-cu12==0.7.0\n",
            "pynvml==12.0.0\n",
            "pyogrio==0.11.0\n",
            "pyomo==6.9.2\n",
            "PyOpenGL==3.1.9\n",
            "pyOpenSSL==24.2.1\n",
            "pyparsing==3.2.3\n",
            "pyperclip==1.9.0\n",
            "pyproj==3.7.1\n",
            "pyproject_hooks==1.2.0\n",
            "pyshp==2.3.1\n",
            "PySocks==1.7.1\n",
            "pyspark==3.5.1\n",
            "pytensor==2.31.7\n",
            "pytest==8.4.1\n",
            "python-apt==0.0.0\n",
            "python-box==7.3.2\n",
            "python-dateutil==2.9.0.post0\n",
            "python-louvain==0.16\n",
            "python-multipart==0.0.20\n",
            "python-slugify==8.0.4\n",
            "python-snappy==0.7.3\n",
            "python-utils==3.9.1\n",
            "pytz==2025.2\n",
            "pyviz_comms==3.0.6\n",
            "PyWavelets==1.8.0\n",
            "PyYAML==6.0.2\n",
            "pyzmq==26.2.1\n",
            "raft-dask-cu12==25.6.0\n",
            "rapids-dask-dependency==25.6.0\n",
            "rapids-logger==0.1.1\n",
            "ratelim==0.1.6\n",
            "referencing==0.36.2\n",
            "regex==2024.11.6\n",
            "requests==2.32.3\n",
            "requests-oauthlib==2.0.0\n",
            "requests-toolbelt==1.0.0\n",
            "requirements-parser==0.9.0\n",
            "rich==13.9.4\n",
            "rmm-cu12==25.6.0\n",
            "roman-numerals-py==3.1.0\n",
            "rpds-py==0.26.0\n",
            "rpy2==3.5.17\n",
            "rsa==4.9.1\n",
            "ruff==0.12.7\n",
            "safehttpx==0.1.6\n",
            "safetensors==0.5.3\n",
            "scikit-image==0.25.2\n",
            "scikit-learn==1.6.1\n",
            "scipy==1.16.1\n",
            "scooby==0.10.1\n",
            "scs==3.2.7.post2\n",
            "seaborn==0.13.2\n",
            "SecretStorage==3.3.3\n",
            "semantic-version==2.10.0\n",
            "Send2Trash==1.8.3\n",
            "sentence-transformers==4.1.0\n",
            "sentencepiece==0.2.0\n",
            "sentry-sdk==2.34.1\n",
            "shap==0.48.0\n",
            "shapely==2.1.1\n",
            "shellingham==1.5.4\n",
            "simple-parsing==0.1.7\n",
            "simplejson==3.20.1\n",
            "simsimd==6.5.0\n",
            "six==1.17.0\n",
            "sklearn-compat==0.1.3\n",
            "sklearn-pandas==2.2.0\n",
            "slicer==0.0.8\n",
            "smart_open==7.3.0.post1\n",
            "smmap==5.0.2\n",
            "sniffio==1.3.1\n",
            "snowballstemmer==3.0.1\n",
            "sortedcontainers==2.4.0\n",
            "soundfile==0.13.1\n",
            "soupsieve==2.7\n",
            "soxr==0.5.0.post1\n",
            "spacy==3.8.7\n",
            "spacy-legacy==3.0.12\n",
            "spacy-loggers==1.0.5\n",
            "spanner-graph-notebook==1.1.6\n",
            "Sphinx==8.2.3\n",
            "sphinxcontrib-applehelp==2.0.0\n",
            "sphinxcontrib-devhelp==2.0.0\n",
            "sphinxcontrib-htmlhelp==2.1.0\n",
            "sphinxcontrib-jsmath==1.0.1\n",
            "sphinxcontrib-qthelp==2.0.0\n",
            "sphinxcontrib-serializinghtml==2.0.0\n",
            "SQLAlchemy==2.0.42\n",
            "sqlglot==25.20.2\n",
            "sqlparse==0.5.3\n",
            "srsly==2.5.1\n",
            "stanio==0.5.1\n",
            "starlette==0.47.2\n",
            "statsmodels==0.14.5\n",
            "stringzilla==3.12.5\n",
            "stumpy==1.13.0\n",
            "sympy==1.13.1\n",
            "tables==3.10.2\n",
            "tabulate==0.9.0\n",
            "tbb==2022.2.0\n",
            "tblib==3.1.0\n",
            "tcmlib==1.4.0\n",
            "tenacity==8.5.0\n",
            "tensorboard==2.19.0\n",
            "tensorboard-data-server==0.7.2\n",
            "tensorflow==2.19.0\n",
            "tensorflow-datasets==4.9.9\n",
            "tensorflow-hub==0.16.1\n",
            "tensorflow-io-gcs-filesystem==0.37.1\n",
            "tensorflow-metadata==1.17.2\n",
            "tensorflow-probability==0.25.0\n",
            "tensorflow-text==2.19.0\n",
            "tensorflow_decision_forests==1.12.0\n",
            "tensorstore==0.1.76\n",
            "termcolor==3.1.0\n",
            "terminado==0.18.1\n",
            "text-unidecode==1.3\n",
            "textblob==0.19.0\n",
            "tf-slim==1.1.0\n",
            "tf_keras==2.19.0\n",
            "thinc==8.3.6\n",
            "threadpoolctl==3.6.0\n",
            "tifffile==2025.6.11\n",
            "tiktoken==0.9.0\n",
            "timm==1.0.19\n",
            "tinycss2==1.4.0\n",
            "tokenizers==0.21.4\n",
            "toml==0.10.2\n",
            "tomlkit==0.13.3\n",
            "toolz==0.12.1\n",
            "torch @ https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl\n",
            "torchao==0.10.0\n",
            "torchaudio @ https://download.pytorch.org/whl/cu124/torchaudio-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl\n",
            "torchdata==0.11.0\n",
            "torchsummary==1.5.1\n",
            "torchtune==0.6.1\n",
            "torchvision @ https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp311-cp311-linux_x86_64.whl\n",
            "tornado==6.4.2\n",
            "tqdm==4.67.1\n",
            "traitlets==5.7.1\n",
            "traittypes==0.2.1\n",
            "transformers==4.54.1\n",
            "treelite==4.4.1\n",
            "treescope==0.1.9\n",
            "triton==3.2.0\n",
            "tsfresh==0.21.0\n",
            "tweepy==4.16.0\n",
            "typeguard==4.4.4\n",
            "typer==0.16.0\n",
            "types-pytz==2025.2.0.20250516\n",
            "types-setuptools==80.9.0.20250529\n",
            "typing-inspection==0.4.1\n",
            "typing_extensions==4.14.1\n",
            "tzdata==2025.2\n",
            "tzlocal==5.3.1\n",
            "uc-micro-py==1.0.3\n",
            "ucx-py-cu12==0.44.0\n",
            "ucxx-cu12==0.44.0\n",
            "umap-learn==0.5.9.post2\n",
            "umf==0.11.0\n",
            "uritemplate==4.2.0\n",
            "urllib3==2.5.0\n",
            "uvicorn==0.35.0\n",
            "vega-datasets==0.9.0\n",
            "wadllib==1.3.6\n",
            "wandb==0.21.0\n",
            "wasabi==1.1.3\n",
            "wcwidth==0.2.13\n",
            "weasel==0.4.1\n",
            "webcolors==24.11.1\n",
            "webencodings==0.5.1\n",
            "websocket-client==1.8.0\n",
            "websockets==15.0.1\n",
            "Werkzeug==3.1.3\n",
            "widgetsnbextension==3.6.10\n",
            "wordcloud==1.9.4\n",
            "wrapt==1.17.2\n",
            "wurlitzer==3.1.1\n",
            "xarray==2025.7.1\n",
            "xarray-einstats==0.9.1\n",
            "xgboost==3.0.3\n",
            "xlrd==2.0.2\n",
            "xxhash==3.5.0\n",
            "xyzservices==2025.4.0\n",
            "yarl==1.20.1\n",
            "ydf==0.13.0\n",
            "yellowbrick==1.5\n",
            "yfinance==0.2.65\n",
            "zict==3.0.0\n",
            "zipp==3.23.0\n",
            "zstandard==0.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"border: 2px solid #D5D8DC; padding: 20px; border-radius: 10px; background-color: #F8F9F9\">\n",
        "\n",
        "<h2 style=\"color:#2E4053\">Conclusión</h2>\n",
        "\n",
        "<p>\n",
        "Este proyecto representó una simulación completa de un flujo de trabajo de <strong>Machine Learning en producción</strong>, estructurado bajo principios sólidos de ingeniería de software dentro de un entorno Jupyter/Colab.\n",
        "</p>\n",
        "\n",
        "<p>\n",
        "Desde la configuración centralizada hasta la predicción de nuevas muestras, se implementaron prácticas reales como:\n",
        "</p>\n",
        "\n",
        "<ul>\n",
        "  <li>Modularización del código mediante archivos virtuales con <code>%%writefile</code>.</li>\n",
        "  <li>Preprocesamiento avanzado con <code>ColumnTransformer</code> y manejo de clases desbalanceadas con <code>SMOTETomek</code>.</li>\n",
        "  <li>Entrenamiento y evaluación de un modelo robusto (<code>RandomForest</code>) con métricas clave.</li>\n",
        "  <li>Predicción sobre datos reales utilizando el pipeline serializado.</li>\n",
        "  <li>Pruebas unitarias, logging, manejo de errores y documentación con <code>type hints</code> y <code>docstrings</code>.</li>\n",
        "  <li>Generación de <code>requirements.txt</code> para asegurar reproducibilidad.</li>\n",
        "</ul>\n",
        "\n",
        "<p>\n",
        "Todo esto demuestra una comprensión profunda de cómo estructurar, documentar, probar y orquestar proyectos de ML en contextos reales. La elección del dataset permitió abordar un problema realista del sector financiero, con variables altamente heterogéneas, valores nulos, y desbalance significativo en la variable objetivo.\n",
        "</p>\n",
        "\n",
        "<p>\n",
        "Este proyecto no solo responde a los requisitos académicos del curso, sino que además prepara una base sólida para futuros despliegues de modelos en entornos reales, como APIs o microservicios de predicción.\n",
        "</p>\n",
        "\n",
        "<p style=\"text-align: right; font-style: italic;\">\n",
        "— Adrián Ortega 😶\n",
        "</p>\n",
        "\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "N1iDGAXHUiVz"
      }
    }
  ]
}